\doxysection{Speeds}
\label{group__PHYSICS__SPEEDS}\index{Speeds@{Speeds}}
Back\+: \doxyref{Physics abstractions }{p.}{group__PHYSICS__ABSTRACTION_PHYSICS_ABSTRACTIONS} Continue\+: \doxyref{Slow currents }{p.}{group__PHYSICS__SLOW__CURRENT_PHYSICS_SLOW_CURRENT} Up\+: \doxyref{Physics notions }{p.}{group__PHYSICS__NOTIONS}

Considering the role of the time, space and matter is the subject of endless debates in science. Considering finite interaction speeds is against using a \char`\"{}nice and classic physics\char`\"{} with its nice mathematical formulas, but omitting the different speeds misled and may mislead research in several fields. Biology produces situations where the complexity of phenomena and the needed carefulness meets the ones needed in cosmology. The difference is that in biology the consequences of phenomena are immediate and they can be studied experimentally.\doxysubsection{Speed in science}\label{group__PHYSICS__SPEEDS_PHYSICS_SPEEDS}
The role of speed and time, particularly in the context of an object\textquotesingle{}s changing location over time, has long held a mystique in the realm of scientific discovery (and recently returned to be mystic again in cosmology). This intrigue can be traced back to historical debates, such as Zeno\textquotesingle{}s paradoxes. The acknowledgement that an object\textquotesingle{}s movement speed can influence our observations is a topic that has sparked significant scientific discourse over the years. In this section, we aim to draw parallels between the historical debate on the finite speed of light and its contemporary implications in various scientific disciplines, such as the finite speed of ionic currents in biology.

In 1676, the Danish astronomer Ole Rømer was making meticulous observations of Jupiter\textquotesingle{}s moon Io and concluded not only that the speed of light is finite, but he measured its value with sufficient accuracy. Rømer never published a formal description of his method, possibly because of the opposition of his bosses, Cassini and Picard, to his ideas. Cassini knew Rømer\textquotesingle{}s idea and the measurement data. However, instead of accepting the finite value on the speed of observation, he made periodic corrections to the tables of eclipses of Io to take account of its irregular orbital motion\+: {\itshape periodically resetting the clock}. The speed of light must remain infinitely large.

However, the theory of finite speed quickly gained support among other natural philosophers of the period, such as Christiaan Huygens and Isaac Newton \cite{Roemer:1676}. Although Newton surely knew that the observation speed was finite, in his \char`\"{}\+Philosophiae Naturalis \+Principiai Mathematica\char`\"{} \cite{NewtonPrincipia:1687}, published in 1687, he decided to refer to observations that they happen \char`\"{}at the same time\char`\"{} despite knowing that what we observe at the same times, happen at different times. Using instant interaction results in \char`\"{}nice\textquotesingle{}\char`\"{} mathematical laws and enables us to describe most of nature\textquotesingle{}s experiences with sufficient accuracy.

Einstein, in 1905, discovered that the speed of observation (in moving reference frames) may play a decisive role in interpreting scientific phenomena. The results he derived using Minkowski-\/coordinates \cite{Minkowski:1908} were counter-\/intuitive, with many unexpected consequences. Instead of introducing improvement(s) or correction(s) to the existing classic principles and methods, he introduced a new principle\+: the finite interaction speed. The {\itshape disciplinary analysis of the reception of Minkowski\textquotesingle{}s Cologne lecture reveals an overwhelmingly positive response on the part of mathematicians, and a decidedly mixed reaction on the part of physicists} \cite{Minkowski100:2008} has turned to the exact opposite. Today, physics generally accepts the description, that is, the existence of finite interaction speed (resulting in the birth of a series of modern science disciplines). However, other science disciplines, including biology and computing science, refute (or at least do not use) it.

Helmholtz, in 1850, sent a short report off to the Academy \cite{HelmholtzReport:1850} "{}I have found that a measurable time passes when the stimulus exerted by a momentary electric current on the hip plexus (Hüftgeflecht) of a frog propagates itself to the nerves of the thigh and enters the calf muscle.\char`\"{} His teacher \char`\"{}had thought that the speed of nervous conduction might be in excess of the speed of light and could probably never be measured. Helmholtz\textquotesingle{}s father, on hearing of the experiment and the surprisingly slow measured speed, wrote to his son that he would as soon believe this result as that one can see the light of a star that burned out a million years ago"{} \cite{HelmoltzHistory:1851}.

With the development of measurement technology, it became evident that finite speed is a general feature of the \char`\"{}nervous connection\char`\"{}. (Somehow, \char`\"{}the speed of nervous conduction\char`\"{} has been renamed to \char`\"{}conduction velocity\char`\"{}, neglecting the clear distinction that physics makes between the two wording.) With the dawn of instrumental electronics and computing, the Mc\+Culloch-\/\+Pitts model \cite{LogicalCalculusMcCulloch:1943} introduced the picture that the brain can be modeled by a network of simple perceptron nodes connected by wires; that is, it comprises a two-\/state equipotential membrane connected with perfect wires. The experimental research also quickly (re-\/)discovered that those wires forward signals in a particular way; the speed of the potential wave (and that of the attached \char`\"{}transversal ion current\char`\"{}) is finite. Furthermore, {\itshape the axons are not equipotential during transmission}. Although its structure is practically identical with axons, {\itshape biology assumes that, unlike an axon, the membrane remains equipotential during its operation, although the evidence shows the opposite }\+: \textquotesingle{}the action potential spreads as a traveling wave from the initial site of depolarization to involve the entire plasma membrane\textquotesingle{} \cite{MolecularBiology:2002}.

When seeing that assuming an equipotential membrane was wrong and a single equipotential surface (in other words, classic physics\textquotesingle{} instant interaction) cannot describe neurons adequately, multi-\/compartment models (typically comprising equipotential cylinders with different potentials) have been introduced \cite{MathNeuroscience:2010}. Then (forgetting that Ohm\textquotesingle{}s Law is valid only for classic physics\textquotesingle{}s \textquotesingle{}instant interaction\textquotesingle{}, furthermore, that no external potential is connected to either of the compartments, and no charge is present at the beginning, except at the input of the first compartment), the individually equipotential compartment pieces were connected by individual resistors. This model shows that the better is the agreement (accuracy) with experiments, the more compartments are used. It happens because the shorter the size of the compartment (approaches a differential equation), the less noticeable the deviation from the true non-\/equipotential surface. This conclusion means that charging the capacitance attached to the compartment takes time, resulting in {\itshape a delayed distributed current}. {\itshape Using infinitely many compartments, we would arrive at the differential equations describing a delayed distributed current on the surface of the non-\/equidistant membrane.} However, biology did entirely not give up its position. {\itshape It admitted that membrane current exists, but only between compartments, and its speed must be infinite} (or, at least, the speed of \doxyref{EM}{p.}{GLOSSARY_GLOSSARY_EM} interaction). However, at least the compartment pieces must be equipotential. Instead of fixing the wrong hypothesis, biology is \char`\"{}periodically resetting the clock\char`\"{}.\doxysubsection{Finite-\/speed interactions}\label{group__PHYSICS__SPEEDS_PHYSICS_SPEEDS_FINITE}
When speaking about speed, especially the speed of charged objects inside neurons, one needs to consider microscopic and macroscopic levels of understanding. On the boundaries of the two levels, we need to make distinctions between different kinds of speeds, among others (in units of $m/s$), the propagation speed $10^{8}$ of the electric field (aka potential), the speed $10^{5}$ of thermal motion, the apparent speed $10^{1}$ of current (as a macroscopic stream, both in metals and electrolytes; furthermore, of neural charge transfer by ions in spikes in axons), $10^{-2}$ for ion current inside a neuron (see Fig. 1 in \cite{ActionPotentialGenerationNatrium:2008}); diffusion speed $10^{-4}$ of electrons in a wire, current drift speed $10^{-7}$ of the individual carriers in aqueous solutions; and $10^{-8}$ of ions moving in a narrow tube filled with viscous liquid. Fortunately, in most {\itshape but not all} cases, different mechanisms (such as the Grotthuss mechanism or free electron model; for a review, see \cite{GrotthussMechanism:2023}) at the level of microscopic structure help to create the illusion of a high macroscopic propagation speed (million times higher than the speed of microscopic carriers). {\itshape The same carrier can have macroscopic speeds differing by orders of magnitude, depending on the context}; a biological example see at \doxyref{ion channels }{p.}{group__MODELING__SINGLE__ION__CHANNEL_MODELING_ION_CHANNEL}. When more than one of those speeds plays a role in the phenomenon we study, we must carefully consider its context and prepare for handling {\itshape fast} and {\itshape slow} effects, and their mixing.

In this section, we discuss mainly currents. {\itshape To deliver current, one needs moving charged particles that need acting of some external (electric, magnetic, or chemical) force or a mixture of forces. We have speeds of \doxyref{EM}{p.}{GLOSSARY_GLOSSARY_EM} interaction, thermal motion of the charge carriers, macroscopic current, drift speed,} and mixing simultaneously in the same phenomenon. In the theoretical description of processes, instant interaction (i.\+e., the abstraction of non-\/physical, infinitely large interaction speed) is used in most cases. In the cases when absolutely needed, the generic notion of \char`\"{}speed\char`\"{} is used without specifying which one of the mentioned speeds it means.

Considering the finite field propagation speed requires revisiting the fundamental physical laws. The famous Coulomb\textquotesingle{}s Law (in a Lorentz-\/transformed form) should be written as

\begin{equation} \frac{F(t)}{Q_{1}}=k\frac{Q_{2}}{r^{2}}(t{-\frac{r}{c}})\label{eq:CoulombTimeDependent} \end{equation}

The electrostatic field that charge $Q_1$ experiences due to the finite propagation speed $c$ of the electric field (or interaction) corresponds to that $Q_2$ at a distance $r$ {\bfseries{generated $\frac{r}{c}$ time ago}} ( $k$ is the constant describing the electric interaction). This term has no role if the two charges do not change their position; similarly to that in the special theory of relativity, only the relative movement leads to complications. If the distance changes, its effect is so tiny that the term can usually be omitted. So, our college knowledge can serve as a good first approximation.

This speed term pops another Law from classical physics into our minds\+: Kirchhoff\textquotesingle{}s junction rule. The law is perfect in the approximation \textquotesingle{}instant interaction\textquotesingle{} that classical physics uses. First, because it expresses charge conservation, {\itshape it is invalid when charges are \char`\"{}created\char`\"{} inside biological objects} (ions diffuse into the junction; see the role of ion channels in the wall of membranes). Second, it is not valid for input currents arriving with finite speeds, but it is valid for a single point in space-\/time (in other words, in differential equation form). The currents (and the voltages), measured at two different points in space-\/time, are different. Consequently, for extended objects (such as a line-\/like finite-\/size neuron), it is valid only with a time delay \begin{equation} I_{out}(t)=-I_{in}(t-\Delta t)\label{eq:Kirchoff_biology} \end{equation}

We can calculate the delay time $\Delta t$ (in a slightly simplified form) classically, from distance $r$ along the path of the current and the macroscopic speed $v$ of the current. Let us consider a 30 cm current path (a wire). The time delay is in the {\itshape nsec} range for \doxyref{EM}{p.}{GLOSSARY_GLOSSARY_EM} propagation speed, but it is in the {\itshape 10 msec range} for the speed calculated from the telegraph equation and measured in metallic wires; furthermore, in the case of axonal current \cite{HodgkinHuxley:1952}, on a 0.\+3 cm distance, it is in the {\itshape 0.\+1 msec range}. Inside a neuron, the current is so slow that the peak-\/to-\/peak temporal distance of an \doxyref{AP}{p.}{GLOSSARY_GLOSSARY_AP} at different places inside the neuron is several times more than the temporal length of the \doxyref{AP}{p.}{GLOSSARY_GLOSSARY_AP}, see Fig. 3f in \cite{ActionPotentialGenerationNatrium:2008}. {\itshape We must not describe the axon or the membrane with the usual Kirchoff equation\+: the input and the output currents flow at different times; only the differential equation form expresses charge conservation}. For its exact interpretation see sections \doxyref{on axonal charge delivery }{p.}{group__MODELING__SINGLE__AXON_AXONAL_CHARGE_DELIVERY} and \doxyref{on the true membrane current}{p.}{group__MODELING__SINGLE__MEMBRANE_MODELING_SINGLE_MEMBRANE_TRUE_CURRENT}, Fig. \doxyref{fig\+\_\+\+The-\/ghost-\/image\+\_\+\+AP}{p.}{group__MODELING__SINGLE__ELECTRIC_fig_The-ghost-image_AP}, and the text around it. {\itshape Studying electric phenomena on structured media, such as biological cells, needs much care}. We must not apply laws derived from entirely different conditions (mainly metals).

Using the cable equation, as Hodgkin and Huxley attempted \cite{HodgkinHuxley:1952}, led to numerical difficulties, and they faced the principal problem\+: their equations assumed infinitely fast electric interaction, and they attempted to combine them with the (unknown) finite macroscopic speed of current in neuronal telegraph cables. The validity of using cable equations for biological objects is at least doubtful\+: deriving a telegrapher equation assumes applying an external potential to the cable filled with charge carriers, and in the case of biological membranes neither external potential nor permanently present charge carriers exist. Furthermore, the cable equation assumes continuous current outflow (a distributed resistance), which is not true for the neuronal membrane (current flows only toward the \doxyref{AIS}{p.}{GLOSSARY_GLOSSARY_AIS}).\doxysubsection{Mixing interaction speeds}\label{group__PHYSICS__SPEEDS_PHYSICS_SPEEDS_MIXING}
It is a mystery in biology that interactions with different speeds play their role {\itshape simultaneously}. The issue forces researchers to give non-\/scientific explanations to everyday phenomena only because {\itshape they routinely assume that the interactions have the same speed, and use the Laws about strictly pair-\/wise interactions}.

During our college studies, we mentioned that light is an electromagnetic wave with a vast but finite propagation speed. Still, we forgot to highlight that, at the same time, it is the propagation speed of the electric (and magnetic and gravitational) interaction force field as well. The effect of \char`\"{}\+Retarded-\/\+Time Potential\char`\"{} is also known in physics and communication engineering. Algorithms \char`\"{}marching-\/on-\/in time\char`\"{} and "{}Analytical Retarded-\/\+Time Potential Expressions are derived to handle the problem; for a discussion, see \cite{RetardedTimePotential:2011}. Telegrapher\textquotesingle{}s equations (also used to describe biological signal transfer) explicitly assume a finite propagation speed millions of times slower than the \doxyref{EM}{p.}{GLOSSARY_GLOSSARY_EM} interaction\textquotesingle{}s. The issue is not confined to large distances\+: designers of micro-\/electronic devices also must consider the effect\+: they introduced clock time domains and clock distribution trees; see, for example \cite{WiringDominance:2019} \cite{VeghRevisingClassicComputing:2021}.

The theoretical model \cite{VeghNeuralShannon:2022} described how the slow operation of biological objects explains biological phenomena, but due to the lack of dedicated measurements it could only indirectly underpin the theory\textquotesingle{}s correctness. Now, we give an exact quantitative explanation of the precise measurements \cite{HodgkinHuxley:1952} \cite{SynapticTransmissionMason:1991}, which have not been correctly understood in the past decades due to the lack of understanding of the role of the finite interaction speed (conduction velocity) in neuronal operation. 